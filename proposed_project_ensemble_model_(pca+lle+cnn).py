# -*- coding: utf-8 -*-
"""Proposed Project - Ensemble Model (PCA+LLE+CNN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18auuD4uphvRM3WqnQwjtD3kdjA5a3Csr

Importing Libraries
"""

# Importing necessary library 
import matplotlib.pyplot as plt 
import numpy as np 
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import GridSearchCV 
from sklearn.datasets import fetch_lfw_people 
from sklearn.metrics import classification_report 
from sklearn.metrics import confusion_matrix 
from sklearn.decomposition import PCA 
from sklearn.svm import SVC

"""Data Preprocessing"""

# reading lfw dataset with minimum 70 faces so as to reduce overfitting
dataset = fetch_lfw_people(min_faces_per_person = 70, resize = 1) 
datapoints, h, w = dataset.images.shape 
print('heights and widths of facial images :',h, w)

#fetching value to X in a vectorized format instead of 2D array
X = dataset.data 
n_features = X.shape[1] 
print('data shape after flattening(number_of_rows,image_height*image_width)',X.shape)

# Id of the person is the label that will be useful in prediction
y = dataset.target 
names = dataset.target_names 
n_classes = names.shape[0] 

# output the details of the lfw dataset 

print("Class Labels (Total number): % d" % n_classes) 
print("Data Sample (Total number): % d" % datapoints) 
print("Data Sample size: % d" % n_features) 

# the label to predict is the id of the person 
y = dataset.target 
names = dataset.target_names 
n_classes = names.shape[0] 

# Print Details about dataset 
print("Number of Data Samples: % d" % datapoints) 
print("Size of a data sample: % d" % n_features) 
print("Number of Class Labels: % d" % n_classes)

"""Plotting Images"""

# plotting images that help understand the dataset better
def plot_gallery(images, title, h, w, n_row = 4, n_col = 5): 
	plt.figure(figsize =(2 * n_col, 3 * n_row)) 
	plt.subplots_adjust(bottom = 0, left =.01, right =.99, top =.90, hspace =.35) # providing dimensions of images to be printed
	for i in range(n_row * n_col): 
		plt.subplot(n_row, n_col, i + 1) 
		plt.imshow(images[i].reshape((h, w)), cmap = plt.cm.gray) # converting it into grey scale
		plt.title(title[i], size = 12) 
		plt.xticks(()) 
		plt.yticks(()) 

# outputing the respective true labels of the images printed
def title(Y, names, i): 
	true_name = names[Y[i]].rsplit(' ', 1)[-1] 
	return 'true label: % s' % (true_name) 
 
#calling the function defined
titles = [title(y, names, i) 
					for i in range(y.shape[0])] 
plot_gallery(X, titles, h, w)

"""Plotting Class distribution"""

# class distribution plot
from collections import Counter 
y_count = Counter(y)
plt.grid()
plt.bar(y_count.keys(),y_count.values())
plt.xlabel('classes')
plt.ylabel('classes_count')
plt.title('class ditribution')
plt.show()

"""Train and Test split"""

# splitting data into train and test
X_train, X_test, y_train, y_test = train_test_split( 
	X, y, test_size = 0.25, random_state = 42,stratify = y) 
print("Training Data size:  % d , and Testing Data Size: % d" %( 
		y_train.shape[0], y_test.shape[0]))

"""Individual Class Weigths"""

# computing class weights
from sklearn.utils.class_weight import compute_class_weight
z = compute_class_weight('balanced',np.unique(y_train),y_train)

weight = dict(zip(range(len(z)),iter(z)))

print(weight)

"""**Dimension Reduction 1 -- PCA**"""

from sklearn.manifold import Isomap
from sklearn.manifold import LocallyLinearEmbedding
from sklearn.decomposition import TruncatedSVD

# number of components have been increased from 80 to 150
n_components = 150

pca = PCA(n_components = n_components, svd_solver ='randomized', whiten = True)

# training data for PCA
X_train_pca = pca.fit_transform(X_train) 

# reshaping the components
eigenfaces = pca.components_.reshape((n_components, h, w)) 

X_test_pca = pca.transform(X_test) 
print('After Transformation')
print('X train : ' ,X_train_pca.shape)
print('X test  : ' ,X_test_pca.shape)

print('explained variance per feature:\n',pca.explained_variance_ratio_)

"""### plotting eigen faces"""

# plotting eigen faces
figu = plt.figure(figsize=(20, 9))
for i in range(30):
    ax = figu.add_subplot(3, 10, i + 1, xticks=[], yticks=[])
    ax.imshow(pca.components_[i].reshape((h, w)),
              cmap=plt.cm.bone)

"""### percentage variance/information retained v/s features"""

var_explained = pca.explained_variance_ratio_;  
cum_var=np.cumsum(var_explained)#plot PCA spectrum   
plt.figure(1,figsize=(6,4))
plt.clf()  
plt.plot(cum_var,linewidth=2)  
plt.axis('tight')  
plt.grid() 
plt.xlabel('n_components') 
plt.ylabel('Cumulative_Variance_explained')  
plt.show()

print("Sampling the datapoints after PCA is applied \n", X_train_pca[0])

"""**Dimension Reduction 2 -- LLE**"""

from sklearn.manifold import Isomap
from sklearn.manifold import LocallyLinearEmbedding
from sklearn.decomposition import TruncatedSVD

# number of components selected is 150 as that is the amount with most data absorption 
n_components = 150

# using lle library functionality as the other dimensionality reduction
lle = LocallyLinearEmbedding(n_components=n_components,n_neighbors=80,n_jobs=-1)

# train and test data transformation for lle
X_train_lle = lle.fit_transform(X_train) 
X_test_lle = lle.transform(X_test) 
print('reconstruction error :',lle.reconstruction_error_)

"""Data Reshape and conversion to categorical for **CNN**"""

import tensorflow as tf

# converting test and train label data categorically so that there is less overfitting
y_train =tf.keras.utils.to_categorical(y_train,num_classes=len(np.unique(y))) 
y_test =tf.keras.utils.to_categorical(y_test,num_classes=len(np.unique(y)))

# reshaping the images to fit the CNN dense layer
X_train = X_train.reshape(-1,dataset.images.shape[1],dataset.images.shape[2])
X_test = X_test.reshape(-1,dataset.images.shape[1],dataset.images.shape[2])

# printing the shapes
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""**CNN Layer**"""

# importing necessary libraries for the CNN dense structure and subsequent ensemble model
from tensorflow.keras.models import Model
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Concatenate,Input,MaxPooling2D,Flatten,BatchNormalization,Dropout

# initialising the seed for CNN
seed=1
np.random.seed(seed)
tf.random.set_seed(seed)

# initialising the various inputs that will be a part of the CNN structure
input0 = Input(shape = (dataset.images.shape[1],dataset.images.shape[1],1))
input1 = Input(shape = (150,))
input2 = Input(shape = (150,))

# extracting features of VGG16 model
model= tf.keras.applications.VGG16(
     include_top=False,
     weights=None,
     input_shape=(dataset.images.shape[1],dataset.images.shape[2],1),
     pooling=max)

# dropout layer is added after each pooling layer to overrcome overfitting
updated_model = Sequential()
for layer in model.layers:
    updated_model.add(layer)
    if layer.name in ['block1_pool', 'block2_pool','block3_pool','block4_pool' ]:
        updated_model.add(Dropout(.3))

model = updated_model

x = Flatten()(model.output)
x = Dropout(.4)(x)
x = Concatenate(axis=-1)([x,input1,input2])
x = Dense(units=512,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),kernel_regularizer=None)(x) 
# x = BatchNormalization()(x)
x = Dense(units=128,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),bias_regularizer=None)(x)
x = Dropout(.4)(x)
x = Dense(units=32,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),bias_regularizer=None)(x)
x = BatchNormalization()(x)
x = Dropout(.4)(x)

x = Dense(units=16,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),bias_regularizer=None)(x)

preds=Dense(len(np.unique(y)),activation='softmax')(x)

model = Model(inputs=(input1,input2,model.input),outputs=preds)
model.summary()

!pip install tensorflow-addons
from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau
import tensorflow_addons as tfa
model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),loss='categorical_crossentropy',metrics=['accuracy',tfa.metrics.F1Score(num_classes=len(np.unique(y)), threshold=0.5,average = 'micro')])

def scheduler(epoch, lr):
  if epoch > 350:
    return lr* 0.01
  else:
    return lr 

# early stopping and reducing the learning rate eventually so that accuracy is improved with every run
monitor = EarlyStopping(monitor='f1_score', min_delta=0.0001, patience=500, 
                        verbose=1, mode='max', restore_best_weights=False,baseline=0.910)
reduce_lr = ReduceLROnPlateau(monitor='val_f1_score', factor=0.01, mode='max',
                              patience=300, min_lr=0.000001,verbose=1)
schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)
callback =[monitor,reduce_lr,schedule]

tf.keras.utils.plot_model(model,show_shapes=True)

"""**Ensemble Model run**"""

# image vectors extracted after using PCA and LLE are combined while running the CNN dense layer 
model_history = model.fit((X_train_pca,X_train_lle,X_train),y_train,batch_size=64,epochs=400,
                    validation_data=((X_test_pca,X_test_lle,X_test),y_test),callbacks = callback,class_weight=weight)

"""Plotting Accuracy and F1 score Graphs"""

plt.figure(figsize = (15,7))
print(model_history.history.keys())
#  Graph - Accuracy
plt.grid()
plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['curacy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.savefig('accuracy')

# "f1"
plt.figure(figsize = (15,7))
plt.grid()
plt.plot(model_history.history['f1_score'])
plt.plot(model_history.history['val_f1_score'])
plt.title('model F1-score')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')

plt.savefig('f1.png')
# "Loss"

plt.figure(figsize = (15,7))
plt.grid()

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')

plt.savefig('loss')